## 1. How Models Work
این اولین قدم برای ورود به دنیای یادگیری ماشینه

### Introduction

کار را با مروری بر نحوه عملکرد مدل‌های یادگیری ماشین و کاربرد آن‌ها شروع می‌کنیم. 

> فرض کنید پسرعموی شما از طریق خرید و فروش ملک، میلیون‌ها دلار سود کرده است. او به دلیل علاقه شما به یادگیری ماشین، پیشنهاد داده که با هم شریک شوید؛ به این صورت که او سرمایه را تأمین کند و شما مدل‌هایی بسازید که قیمت خانه‌های مختلف را پیش‌بینی کنند.

وقتی از پسرعمویتان می‌پرسید که در گذشته چطور قیمت‌ها را پیش‌بینی می‌کرده، می‌گوید که این کار فقط بر اساس «شهود» بوده است. اما با پرس‌وجوی بیشتر مشخص می‌شود که او الگوهای قیمتی را از خانه‌هایی که در گذشته دیده شناسایی کرده و از آن الگوها برای پیش‌بینی قیمت خانه‌های جدید استفاده می‌کند.

یادگیری ماشین هم دقیقاً به همین صورت عمل می‌کند. ما با مدلی به نام **درخت تصمیم (Decision Tree)** شروع خواهیم کرد. مدل‌های پیچیده‌تری هم وجود دارند که پیش‌بینی‌های دقیق‌تری ارائه می‌دهند، اما درک درخت‌های تصمیم ساده است و آن‌ها سنگ‌بنای اصلی برخی از بهترین مدل‌های علم داده محسوب می‌شوند.

برای سادگی، با ابتدایی‌ترین حالتِ ممکنِ یک درخت تصمیم کار را آغاز می‌کنیم.

![[1-1.png]]

این مدل خانه هارو تنها به 2 دسته بندی (بیشتر از 2 اتاق خواب یا کمتر از 2 اتاق خواب) تقسیم میکنه
قیمت پیش‌بینی‌شده برای هر دسته جدید، بر اساس **میانگین قیمت خانه‌های مشابه** در گذشته (که در همان گروه قرار داشتند) محاسبه می‌شود

ما از داده‌ها در دو مرحله استفاده می‌کنیم:
۱. ابتدا برای اینکه بفهمیم خانه‌ها را بر چه اساسی به دو دسته تقسیم کنیم.
۲. سپس برای اینکه قیمت میانگینِ هر گروه را به دست آوریم.

به این فرآیندِ استخراجِ الگو از داده‌ها، **«برازش» (Fitting)** یا **«آموزش مدل» (Training)** می‌گوییم. همچنین به مجموعه‌ی داده‌هایی که برای این کار استفاده می‌شوند، **«داده‌های آموزشی» (Training Data)** گفته می‌شود.

وقتی مدل شما «آموزش» دید، می‌توانید آن را روی خانه‌های جدید اجرا کنید تا قیمت آن‌ها را برایتان **پیش‌بینی (Predict)** کند.

### Improving the Decision Tree

بزرگ‌ترین نقطه ضعف این مدلِ ساده این است که عوامل کلیدی دیگر مثل تعداد سرویس‌های بهداشتی، متراژ زمین و محله را کلاً نادیده می‌گیرد.

برای اینکه بتوانیم این متغیرهای مختلف را هم در پیش‌بینی دخیل کنیم، باید از درختی استفاده کنیم که **تقسیم‌بندی‌های (Splits)** بیشتری داشته باشد. در اصطلاح به این مدل‌ها، درختهای **«عمیق‌تر» (Deeper Trees)** می‌گوییم.

مثلاً اگر بخواهیم علاوه بر تعداد اتاق، «متراژ کل زمین» را هم در مدل لحاظ کنیم، ساختار درخت ما لایه‌های بیشتری پیدا می‌کند و شبیه به این می‌شود:

![[1-2.png]]

برای پیش‌بینی قیمت هر خانه، کافی است ویژگی‌های آن را بردارید و در **درخت تصمیم** مسیر درست را دنبال کنید؛ یعنی در هر مرحله، شاخه‌ای را انتخاب کنید که با مشخصات آن خانه هم‌خوانی دارد.

قیمت نهایی پیش‌بینی‌شده در انتهای این مسیر قرار گرفته است. به این نقاطِ پایانی که دیگر تقسیمی ندارند و پیش‌بینی نهایی را به ما می‌دهند، **«برگ» (Leaf)** می‌گوییم.

اینکه درخت ما در چه نقاطی تقسیم بندی بشه (Splits) و چه اعدادی در «برگ‌ها» قرار بگیرند، تماماً توسط خودِ داده‌ها تعیین می‌شود. پس حالا وقت آن است که برویم سراغ اصل مطلب و نگاهی به داده‌هایی بیندازیم که قرار است با آن‌ها کار کنیم.

## 2. Basic Data Exploration
داده هارو بارگذاری و درک کنید

### Using Pandas to Get Familiar With Your Data

در هر پروژه یادگیری ماشین، قدم اول این است که بفهمید اصلاً با چه داده‌هایی سر و کار دارید. ابزار شماره یک دانشمندان داده برای تحلیل و دستکاری داده‌ها، کتابخانه‌ی **Pandas** است. در دنیای برنامه‌نویسی، معمولاً برای سرعت بیشتر، این کتابخانه را با نام مستعار `pd` فراخوانی می‌کنند:

```python
import pandas as pd
```

قلب تپنده‌ی این کتابخانه، مفهومی به نام **DataFrame** (دیتافریم) است. دیتافریم را مثل یک جدول بزرگ تصور کنید؛ دقیقاً شبیه به یک فایل **Excel** یا جدولی در پایگاه داده **SQL** که سطر و ستون دارد.

پانداز ابزارهای بسیار قدرتمندی دارد که هر بلایی بخواهید سر این جدول‌ها بیاورید (از فیلتر کردن گرفته تا محاسبات پیچیده)، به سادگی برایتان انجام می‌دهد.

برای یادگیری، ما از داده‌های واقعیِ قیمت مسکن در **ملبورن (Melbourne) استرالیا** استفاده می‌کنیم.
فایل داده‌های ملبورن در این مسیر قرار دارد:

`https://raw.githubusercontent.com/itsmecevi/dataset/main/melb_data.csv`

حالا وقت آن است که با چند دستور ساده، این داده‌ها را بارگذاری کرده و داخل آن‌ها را سرک بکشیم:

```python
import pandas as pd

# استفاده از لینک مستقیم داده‌ها در گیت‌هاب به جای دانلود و مسیر لوکال
melbourne_file_path = 'https://raw.githubusercontent.com/SoroushRamezani/Kaggle-Learn/refs/heads/main/data/Melbourne%20Housing%20Snapshot/melb_data.csv'

# خواندن داده‌ها از اینترنت و ذخیره در دیتافریم
melbourne_data = pd.read_csv(melbourne_file_path)

# نمایش خلاصه‌ای از وضعیت داده‌ها
melbourne_data.describe()
```
![[1-3.png]]

### Interpreting Data Description

وقتی آمارهای کلی جدولتان را می‌گیرید، برای هر ستون ۸ عددِ کلیدی نمایش داده می‌شود که تصویر دقیقی از وضعیت داده‌ها به شما می‌دهد:

۱. **تعداد (Count):** این عدد نشان می‌دهد در هر ستون چند خانه‌ی «پُر» داریم. گاهی اوقات داده‌ها **Missing** یا «گم‌شده» هستند؛ مثلاً وقتی دارید اطلاعات یک خانه‌ی یک‌خوابه را ثبت می‌کنید، طبیعی است که ستونِ «متراژ اتاق دوم» خالی بماند. (در آینده یاد می‌گیریم چطور با این خانه‌های خالی برخورد کنیم).

۲. **میانگین (Mean):** همان معدلِ اعدادِ آن ستون است.

۳. **انحراف معیار (Std):** این شاخص نشان می‌دهد که اعداد چقدر از میانگین فاصله دارند و چقدر پراکنده‌اند. (آیا قیمت‌ها همه نزدیک به هم هستند یا تفاوت‌های فاحش دارند؟)
اگه نزدیک به صفر باشه یعنی داده به هم نزدیکن
اگه نزدیک به میانگین باشه یعنی داده های توی یه بازه پراکنده پخش شدن و تفاوت فاحش دارند

۴. **درک بازه‌های قیمتی (چارک‌ها):**

برای درک مقادیر **Min**، **25%**، **50%**، **75%** و **Max**، تصور کنید تمام خانه‌ها را بر اساس قیمت، از ارزان‌ترین تا گران‌ترین پشت سر هم ردیف کرده‌اید:

- **مین (Min):** قیمت ارزان‌ترین خانه در لیست است.
- **25% (صدک ۲۵ام):** عددی است که از ۲۵ درصدِ خانه‌ها گران‌تر و از ۷۵ درصدِ بقیه ارزان‌تر است.
- **50% (میانه):** دقیقاً خانه‌ای که وسط صف ایستاده است! نیمی از خانه‌ها از این قیمت ارزان‌تر و نیمی دیگر گران‌تر هستند.
- **75% (صدک ۷۵ام):** عددی است که از ۷۵ درصدِ خانه‌ها گران‌تر است.
- **مکس(Max)** قیمت گران‌ترین خانه‌ی موجود در داده‌ها است.

### Exercises

حالا وقتشه خودتون تمرین کنید که یاد بگیرید
باید این مراحلی که تا اینجا انجام دادیم رو توی یه دیتاست دیگه (برای شهر آیوا Iowa) انجام بدید

#### Step 1: Loading Data
وقتشه کدی بنویسید که بتونیم باهاش داده هارو بخونیم:
```python
import pandas as pd

# لینک دیتاست روی گیتهاب
iowa_file_path = 'https://raw.githubusercontent.com/SoroushRamezani/Kaggle-Learn/refs/heads/main/data/home%20data%20for%20ml%20course/train.csv'

# حالا شما باید خط پایین رو پر کنید و دیتا رو بخونید
home_data = ...
```

جواب:
```python
home_data = pd.read_csv(iowa_file_path)
```

#### Step 2: Review The Data

یک خط کد بنویسید که خلاصه ای از وضعیت داده هارو نمایش بده:
```python
```

جواب:
```python
home_data.describe()
```
![[1-4.png]]
حالا داده هارو بررسی کنید و به 2 سوال زیر پاسخ بدید:
```python
# چقدره؟ (به عدد صحیح گرد کنید) lot size میانگین اندازه قواره
avg_lot_size = ...

# قدمت جدید ترین خونه چند ساله؟ (سال حال حاضر منهای سال ساخت خونه)
newest_home_age = ...
```

جواب:
```python
avg_lot_size = 10517
newest_home_age = 16
```

## 3. Your First Machine Learning Model
ساخت اولین مدلمون!

### Selecting Data for Modeling

وقتی یک جدول بزرگ (Dataset) جلوی روی شماست، متغیرهای زیادی در آن وجود دارد که ممکن است در نگاه اول گیج‌کننده باشد. برای اینکه غرق در این حجم از اطلاعات نشیم، باید یاد بگیرید چطور داده‌ها را **غربال (filter)** کنیم

قبل از هر چیز، باید بدانید چه اطلاعاتی در اختیار دارید. با دستور `melbourne_data.columns` می‌توانید لیست تمام ستون‌ها (مثل تعداد اتاق، متراژ، قیمت و...) را ببینید.

```python
import pandas as pd

melbourne_file_path = 'https://raw.githubusercontent.com/SoroushRamezani/Kaggle-Learn/refs/heads/main/data/Melbourne%20Housing%20Snapshot/melb_data.csv'

melbourne_data = pd.read_csv(melbourne_file_path)

# نمایش لیست تمام ستون های دیتاست
melbourne_data.columns
```
```output
Index(['Suburb', 'Address', 'Rooms', 'Type', 'Price', 'Method', 'SellerG',
       'Date', 'Distance', 'Postcode', 'Bedroom2', 'Bathroom', 'Car',
       'Landsize', 'BuildingArea', 'YearBuilt', 'CouncilArea', 'Lattitude',
       'Longtitude', 'Regionname', 'Propertycount'],
      dtype='object')
```

گاهی اوقات در داده‌ها، برخی خانه‌ها خالی هستند (مثلاً متراژ یک خانه ثبت نشده است). این خانه‌های خالی می‌توانند مدل ریاضی ما را با خطا مواجه کنند. فعلاً ساده‌ترین کار را انجام می‌دهیم: **پاک کردن کل ردیفی که اطلاعاتش ناقص است.** این کار با دستور `dropna` انجام می‌شود تا یک جدول تمیز و بی‌نقص داشته باشیم:

```python
# حذف ردیف‌ هایی که داده خالی دارند
melbourne_data = melbourne_data.dropna(axis=0)
```
 عدد صفر (`axis=0`) به چه معناست؟

در کتابخانه پانداز، ما دو محور اصلی داریم. عدد `0` یا `1` مشخص می‌کند که عملیات به صورت **افقی** انجام شود یا **عمودی**:

- یا **`axis=0` (سطرها):** به پانداز می‌گوید که عملیات را روی **ردیف‌ها** انجام بده. یعنی اگر یک مقدار خالی پیدا کردی، کل آن «ردیف» (سطر) را از لیست حذف کن.
- 
- یا **`axis=1` (ستون‌ها):** اگر به جای صفر، یک بگذارید، پانداز کل آن **ستون** را حذف می‌کند. مثلاً اگر در کل جدول، فقط متراژ یک خانه ثبت نشده باشد، پانداز کل ستون «متراژ» را برای همه خانه‌ها پاک می‌کند!

در هر پروژه یادگیری ماشین، ما دنبال پیش‌بینی یک چیز خاص هستیم. در اینجا هدف ما پیش‌بینی **قیمت** است.

- در دنیای کدنویسی، این هدف را با متغیر **y** نشان می‌دهیم.
- برای جدا کردن ستون قیمت، از روش «نقطه» استفاده می‌کنیم: `y = data.Price`
- حالا این ستون قیمت، در یک قالب ساده‌تر به نام **Series** ذخیره می‌شود (که همان جدول تک‌ستونه است).

```python
y = melbourne_data.Price
```

### Choosing "Features"

به ستون‌هایی که به عنوان ورودی به مدل می‌دهیم تا بر اساس آن‌ها پیش‌بینی کند، **«ویژگی» (Feature)** می‌گوییم. در واقع، ویژگی‌ها همان اطلاعاتی هستند که فکر می‌کنیم روی قیمت خانه تاثیر مستقیم دارند.

گاهی اوقات وسوسه می‌شویم که تمام ستون‌های جدول را به مدل بدهیم، اما هنر اینه که هوشمندانه عمل کنیم؛ چون گاهی اوقات دادن اطلاعات زیاد و بی‌اهمیت، مدل را گیج کرده و دقتش را پایین می‌آورد.

چطور ویژگی‌ها را انتخاب کنیم؟

فعلاً برای شروع، فقط چند ویژگی کلیدی که به نظرمان منطقی‌تر می‌آیند (مثل تعداد اتاق، متراژ و موقعیت جغرافیایی) را انتخاب می‌کنیم. در آینده یاد می‌گیرید که چطور با روش‌های ریاضی، بهترین ستون‌ها را به صورت خودکار پیدا کنید.

برای انتخاب چند ستون، نام آن‌ها را در قالب یک «لیست» به پانداز می‌دهیم:

```python
# طول جغرافیایی، عرض جغرافیایی، مساحت زمین، تعداد حمام و دستشویی، تعداد اتاق
melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude']

X = melbourne_data[melbourne_features]
```

چرا از نام X استفاده می‌کنیم؟

طبق یک قرارداد جهانی در علم داده:

- حرف **X**: نشان‌دهنده ورودی‌ها یا همان «ویژگی‌ها» است (چون معمولاً یک لیست از چند مقدار است، از حرف بزرگ استفاده می‌شود).

- حرف **y**: نشان‌دهنده خروجی یا همان «هدف» است (چون معمولاً یک ستون واحد است، از حرف کوچک استفاده می‌شود).

یک قانون طلایی وجود دارد: **هرگز به داده‌های خام اعتماد نکنید.** همیشه قبل از آموزش مدل، از دو دستور زیر استفاده کنید:

- دستور **`()X.describe`**: برای اینکه مطمئن شوید اعداد منطقی هستند (مثلاً متراژ منفی یا تعداد اتاقِ غیرعادی نداشته باشید).

- دستور **`()X.head`**: برای اینکه مطمئن شوید ظاهر جدول درست است و ستون‌ها جابجا نشده‌اند.

```python
# نمایش خلاصه‌ای از وضعیت داده‌ها
X.describe()
```
![[1-5.png]]

```python
# نمایش سر یا همون هد داده ها (5 سطر اول)
X.head()
```
![[1-6.png]]
### Building Your Model

۴ مرحله اصلی برای ساخت هر مدل هوش مصنوعی:
برای اینکه به کامپیوتر یاد بدهید چیزی را پیش‌بینی کند (با استفاده از کتابخانه **Scikit-learn**)، همیشه این ۴ مرحله را طی می‌کنید:

۱. **تعریف (Define):** انتخاب می‌کنید که از چه نوع «مغز» یا الگوریتمی استفاده شود؟ (مثلاً در اینجا ما از **درخت تصمیم** استفاده کردیم)

۲. **آموزش (Fit):** این مهم‌ترین بخش است! داده‌ها را به مدل می‌دهید تا الگوها را کشف کند. مثل این است که هزاران مثالِ حل شده را جلوی مدل بگذارید تا یاد بگیرد قیمت‌ها چطور تعیین می‌شوند

۳. **پیش‌بینی (Predict):** حالا که مدل یاد گرفته، از او می‌خواهیم برای خانه‌های جدید قیمت بگذارد

۴. **ارزیابی (Evaluate):** در نهایت چک می‌کنیم که مدل چقدر درست حدس زده و چقدر خطا داشته است.

در اینجا مثالی از تعریف یک مدل «درخت تصمیم» و آموزش (Fit) آن با استفاده از ویژگی‌ها (X) و متغیر هدف (y) آورده شده است:

```python
from sklearn.tree import DecisionTreeRegressor

# تعریف مدل درخت تصمیم
melbourne_model = DecisionTreeRegressor(random_state=1)

# آموزش مدل با استفاده از ویژگی ها و لیبل
melbourne_model.fit(X, y)
```

بسیاری از مدل‌های یادگیری ماشین در فرآیند آموزش، کمی از «تصادف» یا شانس استفاده می‌کنند. تعیین یک عدد برای `random_state` تضمین می‌کند که شما در هر بار اجرای کد، دقیقاً همان نتایج قبلی را بگیرید. این یک «عادت خوب» در برنامه‌نویسی است. می‌توانید هر عددی بگذارید؛ کیفیت مدل شما تغییر چندانی با تغییر این عدد نمی‌کند.

الان مدل ما روی داده ها آموزش دید و یاد گرفت
برای اینکه مطمئن شویم دستور پیش‌بینی (`predict`) درست کار می‌کند، ویژگی های ۵ خانه اولِ جدولمان را به مدل می‌دهیم و می‌گوییم: «بدون اینکه به قیمت واقعی نگاه کنی، بگو این خانه‌ها چند می‌ارزند؟»

```python
print("ویژگی های 5 خانه اول")
print(X.head())
print("لیبل(قیمت) های 5 خانه اول")
print(y.head())
print("پیش بینی مدل از قیمت 5 خانه اول با توجه به ویژگی ها")
print(melbourne_model.predict(X.head()))
```
![[1-7.png]]
### Exercises

بیاید مرور کنیم توی تمرین قبلی چه کدی نوشتیم:

```python
import pandas as pd

iowa_file_path = 'https://raw.githubusercontent.com/SoroushRamezani/Kaggle-Learn/refs/heads/main/data/home%20data%20for%20ml%20course/train.csv'

home_data = pd.read_csv(iowa_file_path)
```

#### Step 1: Specify Prediction Target

یک کد بنویسید که اسم ستون هارو لیست کنه که بتونید اسم ستون هدف (لیبل) رو پیدا کنید:
```python
```

جواب:
```python
home_data.columns
```
![[1-8.png]]
ستون هدف (لیبل) رو پیدا کنید:
```python
y = ...
```

جواب:
```python
y = home_data.SalePrice
```

#### Step 2: Create X

حالا باید یه دیتافریم درست کنید که شامل ستون های ویژگی باشه
همانطور که یادتونه ما از همه ستون ها استفاده نمیکنیم و از بعضی هاشون نسبت به میزان اهمیتی که دارن استفاده میکنیم که اینها هستند:
**LotArea** متراژ زمین
**YearBuilt** سال ساخت
**1stFlrSF** متراژ طبقه اول
**2ndFlrSF** متراژ طبقه دوم)
**FullBath** تعداد حمام‌های کامل
**BedroomAbvGr** تعداد اتاق‌خواب‌های بالای همکف 
**TotRmsAbvGrd** کل اتاق‌های بالای همکف

```python
# ساخت لیستی از ویژگی ها
feature_names = [...]

# هستند، ستونشون رو به عنوان ویژگی از دیتاست جدا کنید feature_names نام هایی که در
X = ____
```

جواب

```python
feature_names = ["LotArea", "YearBuilt", "1stFlrSF", "2ndFlrSF", "FullBath", "BedroomAbvGr", "TotRmsAbvGrd"]

X=home_data[feature_names]
```

حالا بیاید یه نگاه به ویژگی هامون بندازیم:
```python
# دیدن مشخصات آماری داده ها
print(...)

# دیدن 7 سطر اول داده ها
print(...)
```

جواب:
```python
print(X.describe())

print(X.head(7))
```

#### Step 3: Specify and Fit Model

حالا یه مدل درخت تصمیم `DecisionTreeRegressor` بسازید و اونو روی داده هامون آموزش بدید:
```python
# ابتدا مدل را از سایکیت لرن ایمپورت کنید
from ... import ...
# اینجا مدل را تعریف کنید
# برای اینکه نتایج یکسان و همچنین قابلیت تولید دوباره داشته باشه
# رو بذارید 1 random_state بیاید
iowa_model = ____

# حالا مدل را آموزش بدید
...
```

جواب:
```python
from sklearn.tree import DecisionTreeRegressor

iowa_model = DecisionTreeRegressor(random_state=1)

iowa_model.fit(X, y)
```

#### Step 4: Make Predictions

حالا که مدل آموزش دید با استفاده از دستور `predict` بیاید داده های `X` رو به عنوان ورودی به مدل آموزش دیده بدید و ببینید چه قیمتی خروجی میده و با خروجی اصلی مقایسه کنید
```python
# بدست میاره X این کد پیش بینی قیمت خونه هارو نسبت به ورودی 
predictions = ...
print(predictions)

# مقادیر اصلی قیمت خونه ها 
print(...)
```

جواب:
```python
predictions = iowa_model.predict(X)

print(y)
```


## 4. Model Validation
اندازه گیری عملکرد مدل

### What is Model Validation

شما یک مدل ساخته‌اید، اما از کجا معلوم که در دنیای واقعی درست کار کند؟ سنجش کیفیت مدل، تنها راهی است که به شما می‌گوید آیا نیاز به تغییر در مدل دارید یا خیر.
شما تقریباً برای هر مدلی که می‌سازید، نیاز به ارزیابی دارید. در بیشتر کاربردها (نه همه آن‌ها)، معیار اصلی کیفیت، **دقت پیش‌بینی (accuracy)** است؛ یعنی آیا پیش‌بینی‌های مدل به آنچه در واقعیت اتفاق می‌افتد نزدیک است یا خیر؟

بسیاری از مبتدی‌ها مرتکب یک **اشتباه مرگبار** می‌شوند: آن‌ها مدل را با یک سری داده آموزش می‌دهند و بعد با همان داده‌ها هم از مدل امتحان می‌گیرند! این کار درست مثل این است که معلم، دقیقاً همان سوالاتی را در امتحان بدهد که دیروز در کلاس حل کرده بود. دانش‌آموز ممکن است بدون اینکه ذره‌ای از ریاضی بفهمد، فقط جواب‌ها را **حفظ** کرده باشد.

برای اینکه بفهمیم چقدر با واقعیت فاصله داریم، از معیاری به نام **MAE** (میانگینِ قدر مطلق خطا) استفاده می‌کنیم.

- **فرمول ساده:** `قیمت واقعی - قیمت پیش‌بینی شده = خطا`
- اگر خانه‌ای ۱ میلیارد می‌ارزد و شما حدس زدید ۸۰۰ میلیون، خطای شما ۲۰۰ میلیون است.
- ما تمام این خطاها را مثبت می‌کنیم (قدر مطلق) و از آن‌ها میانگین می‌گیریم.

**نتیجه نهایی MAE به زبان ساده:** اگر عدد MAE مدل شما ۵۰ میلیون تومان شود، یعنی: «مدل من به طور متوسط در هر پیش‌بینی، حدود ۵۰ میلیون تومان اشتباه می‌کند.»

بیاید مرور کنیم دفعه پیش چه کدی نوشتیم:
```python
import pandas as pd

melbourne_file_path = 'https://raw.githubusercontent.com/SoroushRamezani/Kaggle-Learn/refs/heads/main/data/Melbourne%20Housing%20Snapshot/melb_data.csv'
melbourne_data = pd.read_csv(melbourne_file_path) 
filtered_melbourne_data = melbourne_data.dropna(axis=0)

y = filtered_melbourne_data.Price
melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', 'YearBuilt', 'Lattitude', 'Longtitude']
X = filtered_melbourne_data[melbourne_features]

from sklearn.tree import DecisionTreeRegressor
melbourne_model = DecisionTreeRegressor(random_state = 1)
melbourne_model.fit(X, y)
```

حالا میتونیم با کد زیر **MAE** رو حساب کنیم:
```python
from sklearn.metrics import mean_absolute_error

# انجام پیش بینی روی داده ها
predicted_home_prices = melbourne_model.predict(X)

# محاسبه میانگین قدر مطلق خطا با مقایسه قیمت اصلی و قیمت پیش بینی شده توسط مدل
mean_absolute_error(y, predicted_home_prices)
```
```output
434.71594577146544
```

### The Problem with "In-Sample" Scores

سنجشی که ما همین الان انجام دادیم، یک امتیاز «درون-نمونه‌ای» نامیده می‌شود. دلیل این نام‌گذاری این است که ما از یک «نمونه» واحد از خانه‌ها، هم برای ساختن مدل و هم برای ارزیابی آن استفاده کردیم. اما چرا این کار اشتباه است؟

چرا این کار خطرناک است؟

بیایید فرض کنیم در بازار واقعی مسکن، «رنگ درِ خانه» هیچ تاثیری روی قیمتش ندارد. اما به صورت کاملاً اتفاقی، در لیستِ خانه‌هایی که شما به مدل دادید، ۵ خانه‌ای که «درِ سبز» داشتند، همگی اتفاقاً بسیار گران‌قیمت بودند.

1. **مدل چه فکری می‌کند؟** مدل چون وظیفه‌اش پیدا کردن الگوست، با خودش می‌گوید: «آها! پیدا کردم! هر خانه‌ای که درش سبز باشد، قیمتش نجومی است!»
2. **نتیجه در آموزش:** وقتی از مدل درباره همان خانه‌ها بپرسید، جواب‌های دقیقی می‌دهد و شما فکر می‌کنید عجب مدل باهوشی ساخته‌اید!
3. **شکست در دنیای واقعی:** فردا اگر یک خانه معمولی با درِ سبز را به مدل بدهید، مدل به اشتباه قیمتی بسیار بالا برای آن پیش‌بینی می‌کند؛ چون این الگوی «در سبز» در واقعیت وجود ندارد و فقط یک اتفاق تصادفی در داده‌های آموزشی شما بوده است

از آنجایی که ارزشِ واقعیِ یک مدل به توانایی آن در پیش‌بینی روی **داده‌های جدید** است، ما باید عملکرد آن را روی داده‌هایی بسنجیم که در فرآیند ساخت مدل استفاده نشده‌اند. ساده‌ترین راه برای این کار این است که بخشی از داده‌ها را از فرآیند آموزش کنار بگذاریم و سپس از آن‌ها برای تست کردن دقت مدل روی داده‌هایی که قبلاً ندیده است، استفاده کنیم. به این داده‌ها، **داده‌های اعتبارسنجی (Validation Data)** می‌گویند.

### Coding It

کتابخانه scikit-learn تابعی به نام `train_test_split` دارد که داده‌ها را به دو بخش تقسیم می‌کند. ما از بخشی از این داده‌ها به عنوان **داده‌های آموزشی (training data)** برای آموزش (Fit) مدل استفاده می‌کنیم و از بخش دیگر به عنوان **داده‌های اعتبارسنجی (validation data)** برای محاسبه‌ی **میانگین قدر مطلق خطا (MAE)** بهره می‌بریم.

```python
from sklearn.model_selection import train_test_split

# تقسیم داده‌ها به دو بخش آموزشی و اعتبارسنجی، هم برای ویژگی‌ها و هم برای هدف
# دادن یک عدد یکسان به آرگومان random_state تضمین می‌کند که هر بار با اجرای این کد، تقسیم‌بندی یکسانی داشته باشیم.
train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 1)

# تعریف مدل با رندوم استیت برای بازتولید با نتیجه یکسان
melbourne_model = DecisionTreeRegressor(random_state = 1)

# آموزش مدل با داده‌های آموزشی
melbourne_model.fit(train_X, train_y)

# دریافت قیمت‌های پیش‌بینی شده روی داده‌های اعتبارسنجی
val_predictions = melbourne_model.predict(val_X)

# محاسبه و چاپ میزان خطا
print(mean_absolute_error(val_y, val_predictions))
```
```output
251876.65138799226
```

خروجی این کد عددی نزدیک به **250,000 دلار** است! یادتان هست قبل از اینکه داده‌ها را جدا کنیم، خطا فقط 500 دلار بود؟ آن 500 دلار یک **تقلب** بود با داده های درون نمونه ای؛ چون مدل جواب‌ها را از قبل می‌دانست.

حالا که با داده‌های جدید از مدل امتحان گرفتیم، چهره‌ی واقعی‌اش فاش شد:

- مدل ما در هر پیش‌بینی حدود 250 هزار دلار اشتباه می‌کند.
- با توجه به اینکه میانگین قیمت خانه‌ها ۱.۱ میلیون دلار است، این یعنی مدل حدود **۲۵ درصد** خطا دارد!
- **نتیجه:** این مدل فعلاً برای دنیای واقعی «افتضاح» است و نمی‌توان روی پیش‌بینی‌هایش سرمایه‌گذاری کرد.

هدف از این کار این بود که بفهمیم مدلمان واقعاً چقدر توانایی دارد. حالا که فهمیدیم خطای ما 250 هزار دلار است، یک **«نقطه شروع»** داریم. از اینجا به بعد، تمام تلاش ما در علم داده این است که با تغییر دادن مدل، این عدد را از 250 هزار دلار پایین و پایین‌تر بیاوریم

### Exercise

ما توی تمرین های قبلی یک مدل ساختیم، اندفعه میخوایم بفهمیم این مدل چقدر خوب کار میکنه و چقدر خطا داره

اول بیاید مرور کنیم تا تمرین قبلی چه کدی نوشته بودیم:
```python
import pandas as pd
from sklearn.tree import DecisionTreeRegressor

iowa_file_path = 'https://raw.githubusercontent.com/SoroushRamezani/Kaggle-Learn/refs/heads/main/data/home%20data%20for%20ml%20course/train.csv'

home_data = pd.read_csv(iowa_file_path)
y = home_data.SalePrice
feature_columns = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']
X = home_data[feature_columns]


iowa_model = DecisionTreeRegressor(random_state = 1)
iowa_model.fit(X, y)

print("پنج پیش بینی اول مدل از قیمت ها: ", iowa_model.predict(X.head()))
print("قیمت های واقعی داده: ", y.head().tolist())
```
```output
پنج پیش بینی اول مدل از قیمت ها:  [208500. 181500. 223500. 140000. 250000.]
قیمت های واقعی:  [208500, 181500, 223500, 140000, 250000]
```

#### Step 1: Split Your Data

برای تمرین اول با استفاده از تابع `train_test_split` سایکیت لرن بیاید و داده هارو تقسیم کنید
یادتون نره `random_state=1` هم به تابع بدید که هربار به یک صورت تقسیم کنه:
```python
# اول تابع تقسیم بندی رو ایمپورت کنید
from ... import ...

# حالا داده هارو به داده های تمرین و داده های اعتبارسنجی تقسیم کنید
train_X, val_X, train_y, val_y = ...
```

جواب:
```python
from sklearn.model_selection import train_test_split
train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)
```

#### Step 2: Specify and Fit the Model

حالا یک مدل `DecisionTreeRegressor` جدید تعریف کنید و با داده های تقسیم شده مخصوص آموزش، آموزشش بدید:
```python
# رو ایمپورت کرده بودیم پس دوباره لازم نیست DecisionTreeRegressor توی کد بالا
# مدل جدید رو با رندوم استیت تعریف کنید
iowa_model = ...

# مدل رو با داده های آموزشی تمرین بدید
____
```

جواب:

```python
iowa_model = DecisionTreeRegressor(random_state=1)
iowa_model.fit(train_X, train_y)
```

#### Step 3: Make Predictions with Validation data

وقتشه مدل رو با داده های اعتبارسنجی امتحان کنید:
```python
# پیش بینی مدل از داده های اعتبارسنجی
val_predictions = ...
```

جواب:
```python
val_predictions = iowa_model.predict(val_X)
```

حال میایم با چاپ کردن مقادیر اونهارو مقایسه میکنیم:
```python
# چاپ ۵ پیش‌ بینی اول
print("Predictions:    ", val_predictions[:5])

# چاپ ۵ مقدار واقعی اول
print("Actual values:  ", val_y[:5].tolist())
```
```output
Predictions:     [186500. 184000. 130000.  92000. 164500.]
Actual values:   [231500, 179500, 122000, 84500, 142000]
```

همانطور که میبینید اختلاف بین مقادیر خیلی زیاده، در صورتی که موقعی که مدل رو با داده های درون نمونه ای آموزش و تست میکردیم اختلافی وجود نداشت و دقیق بود (چون تقلب میکرد و واقعا خوب یاد نگرفته بود)

#### Step 4: Calculate the Mean Absolute Error in Validation Data

حالا وقتشه **MAE** رو حساب کنید:
```python
from sklearn.metrics import mean_absolute_error
val_mae = ...

# حالا چاپ میکنیم ببینیم چقدره
print(val_mae)
```

جواب:
```python
val_mae = mean_absolute_error(val_y, val_predictions)
```
```Output
29652.931506849316
```

همانطور که میبینید مدل ما وقتی پیش بینی میکنه به صورت میانگین تقریبا 30 هزار واحد (دلار) خطا داره
نگران نباشید، قراره بهترش کنیم!

## 5. Underfitting and Overfitting
تنظیم **(Fine-tune)** مدل برای عملکرد بهتر

### Experimenting With Different Models

س